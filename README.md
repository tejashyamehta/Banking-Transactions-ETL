# Banking Transactions ETL & Dashboard

A **fresher-friendly data engineering project** that simulates banking transactions, processes them via an **ETL pipeline**, stores them in a **SQLite warehouse**, and visualizes insights with a **Streamlit dashboard**.

---

## ğŸ“Œ Overview
This project demonstrates:
- **ETL pipeline** (Extract â†’ Transform â†’ Load)
- **Data cleaning & enrichment**
- **Anomaly detection** (fraud indicators)
- **Data warehousing** concepts
- **Interactive analytics dashboard** with Streamlit

It is designed to be **simple to run locally**, yet follows patterns similar to **real-world banking/fintech pipelines**.

---

## âš™ï¸ Features
- **Synthetic transaction generation** (with edge cases for anomalies)
- **ETL pipeline**:
  - **Extract**: Read all raw CSVs
  - **Transform**: Fix types, derive features (`txn_hour`, `is_high_value`)
  - **Anomaly detection rules**:
    - `HIGH_VALUE`: amount > â‚¹50,000
    - `RAPID_REPEAT`: â‰¥3 txns by same account within 60 seconds
    - `NON_POSITIVE_AMOUNT`: amount â‰¤ 0
  - **Load**: Append clean + anomaly data into SQLite warehouse
- **Streamlit dashboard**:
  - KPIs (total transactions, anomalies, unique accounts)
  - Anomalies by reason (bar chart)
  - Top merchant categories (table)
  - Hourly transaction trends (line chart)
  - Expanders for raw data preview
- **Unit test** for transform logic
- **GitHub Actions CI** to run tests on push/PR

---

## ğŸ—‚ File Structure
banking-etl/
â”œâ”€ src/
â”‚ â”œâ”€ init.py
â”‚ â”œâ”€ db.py # DB engine + schema init
â”‚ â”œâ”€ generate_transactions.py
â”‚ â”œâ”€ etl_pipeline.py
â”‚ â””â”€ dashboard.py
â”‚
â”œâ”€ data/
â”‚ â”œâ”€ raw/ # Generated CSV batches
â”‚ â””â”€ warehouse.db # SQLite data warehouse
â”‚
â”œâ”€ sql/
â”‚ â”œâ”€ schema.sql
â”‚ â””â”€ queries.sql
â”‚
â”œâ”€ tests/
â”‚ â””â”€ test_transform.py
â”‚
â”œâ”€ .github/workflows/ci.yml
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â””â”€ README.md

yaml
Copy
Edit

---

## ğŸ“¸ Architecture
![ETL Pipeline Diagram](docs/etl_pipeline.png)

---

## ğŸš€ Setup & Run

```bash
# 1ï¸âƒ£ Clone repo & enter folder
git clone https://github.com/yourusername/banking-etl.git
cd banking-etl

# 2ï¸âƒ£ Create & activate virtual environment
# Windows PowerShell
python -m venv venv
venv\Scripts\Activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Generate transactions
python -m src.generate_transactions --n 5000

# 5ï¸âƒ£ Run ETL
python -m src.etl_pipeline

# 6ï¸âƒ£ View dashboard
streamlit run src/dashboard.py
ğŸ“Š Example Dashboard Screenshots
(Add screenshots here after running the dashboard)

ğŸ“ˆ Future Scope & Scaling
This project is intentionally lightweight but can scale to production-level pipelines by:

Storage upgrade: SQLite â†’ PostgreSQL, MySQL, or cloud warehouses (Snowflake, Redshift, BigQuery)

Processing upgrade: Pandas â†’ PySpark/Dask for large datasets

Orchestration: Manual run â†’ Apache Airflow or Prefect DAG

Streaming: Batch â†’ Real-time ingestion with Kafka, AWS Kinesis

Data lake: Store raw/processed in AWS S3, Azure Data Lake, or GCP Cloud Storage

Monitoring & alerts: Auto-detect anomalies and send alerts via email/Slack

Dashboards: Streamlit â†’ Tableau, Power BI, Looker